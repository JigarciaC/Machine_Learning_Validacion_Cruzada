{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "* El aprendizaje automático es un proceso iterativo.\n",
    "* Tendrá que elegir:\n",
    "  * qué variables predictivas utilizar,\n",
    "  * qué tipos de modelos utilizar,\n",
    "  * qué argumentos proporcionar a esos modelos, etc.\n",
    "* Hasta ahora, **ha tomado estas decisiones basándose en datos midiendo la calidad del modelo con una validación** ( o reserva) configurado.\n",
    "* Pero este enfoque tiene algunos inconvenientes.\n",
    "* Para ver esto, imaginemos que se tiene un conjunto de datos con 5000 filas.\n",
    "* Normalmente se mantendrá aproximadamente el 20% de los datos como conjunto de datos de validación, o 1000 filas.\n",
    "* Pero **esto deja cierta posibilidad aleatoria a la hora de determinar las puntuaciones del modelo**.\n",
    "* Es decir, un modelo podría funcionar bien en un conjunto de 1000 filas, incluso si sería inexacto en 1000 filas diferentes.\n",
    "* En un caso extremo, podría imaginarse tener solo 1 fila de datos en el conjunto de validación.\n",
    "* Si se comparan modelos alternativos, cuál hace las mejores predicciones sobre un único punto de datos será principalmente una cuestión de suerte.\n",
    "* En general, **cuanto mayor sea el conjunto de validación, menos aleatoriedad (también conocida como \"ruido\") habrá en nuestra medida de la calidad del modelo y más confiable será**.\n",
    "* Desafortunadamente, solo podemos obtener un conjunto de validación grande eliminando filas de nuestros datos de entrenamiento, ¡**y conjuntos de datos de entrenamiento más pequeños significan peores modelos!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es la validación cruzada?\n",
    "* En la validación cruzada, ejecutamos nuestro **proceso de modelado en diferentes subconjuntos de datos para obtener múltiples medidas de la calidad del modelo**.\n",
    "* Por ejemplo, podríamos comenzar dividiendo los datos en 5 partes, cada una de las cuales representa el 20% del conjunto de datos completo. En este caso decimos que hemos dividido los datos en 5 \"pliegues\".\n",
    "* En este caso, tendriamos 5 experimentos, cada uno utilizando una parte como datos de validacion y el resto como datos de entrenamientos.\n",
    "\n",
    "Luego, realizamos un experimento para cada pliegue:\n",
    "\n",
    "* En el **Experimento 1**, utilizamos el primer pliegue como conjunto de validación (o reserva) y todo lo demás como datos de entrenamiento.\n",
    "* Esto nos da una medida de la calidad del modelo basada en un conjunto de reservas del 20%.\n",
    "* En el **Experimento 2**, guardamos datos del segundo pliegue (y usamos todo excepto el segundo pliegue para entrenar el modelo).\n",
    "* Luego, el conjunto de validación (reservas) se utiliza para obtener una segunda estimación de la calidad del modelo.\n",
    "* Repetimos este proceso, usando cada pliegue una vez como conjunto de reserva.\n",
    "* En conjunto, el 100% de los datos se usa como validación (reserva) en algún momento, y terminamos con una medida de la calidad del modelo que se basa en todas las filas del conjunto de datos (incluso si no usamos todas las filas simultáneamente) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cuándo debería utilizar la validación cruzada?\n",
    "* La validación cruzada brinda una medida más precisa de la calidad del modelo, lo cual es especialmente importante si se toman muchas decisiones de modelado.\n",
    "* Sin embargo, puede tardar más en ejecutarse porque estima varios modelos (uno para cada pliegue).\n",
    "* Entonces, dadas estas compensaciones, **¿cuándo debería utilizar cada enfoque?**\n",
    "  * Para **conjuntos de datos pequeños**, donde la carga computacional adicional no es gran cosa, **debe ejecutar una validación cruzada**.\n",
    "  * Para **conjuntos de datos más grandes**, **un único conjunto de validación es suficiente.**\n",
    "* Su código se ejecutará más rápido y es posible que tenga suficientes datos como para que no sea necesario reutilizar algunos de ellos para reservarlos.\n",
    "* No existe un umbral sencillo para determinar qué constituye un conjunto de datos grande o pequeño.\n",
    "* Pero **si su modelo tarda un par de minutos o menos en ejecutarse**, probablemente valga la pena **cambiar a la validación cruzada**.\n",
    "* Alternativamente, puede ejecutar una validación cruzada y ver si las puntuaciones de cada experimento parecen cercanas.\n",
    "* Si cada experimento arroja los mismos resultados, probablemente un único conjunto de validación sea suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada y la función cross_val_score()\n",
    "* Obtenemos las puntuaciones de validación cruzada con la función **cross_val_score()** de scikit-learn.\n",
    "* Establecemos el número de pliegues con el parámetro cv.\n",
    "\n",
    "**Utilidad de cross_val_score()**\n",
    "\n",
    "* La función cross_val_score() de Scikit-Learn se utiliza para evaluar el rendimiento de un modelo de Machine Learning utilizando validación cruzada.\n",
    "* La validación cruzada es una técnica que divide el conjunto de datos en múltiples subconjuntos (folds) para entrenar y evaluar el modelo de manera iterativa, asegurando que cada subconjunto se utilice tanto para el entrenamiento como para la evaluación.\n",
    "* Esto proporciona una estimación más robusta del rendimiento del modelo comparado con un simple split de entrenamiento y prueba.\n",
    "\n",
    "**Ventajas de cross_val_score()**\n",
    "\n",
    "* **Estimación Más Robusta**: Al evaluar el modelo en múltiples subconjuntos de los datos, se obtiene una estimación del rendimiento que es menos dependiente de una sola partición de datos.\n",
    "* **Reducción del Overfitting**: Ayuda a detectar y reducir el overfitting, ya que el modelo se entrena y se evalúa en diferentes porciones del conjunto de datos.\n",
    "* **Uso Eficiente de los Datos**: Aprovecha todo el conjunto de datos tanto para el entrenamiento como para la evaluación, lo que es particularmente útil cuando se dispone de un conjunto de datos limitado.\n",
    "* **Comparación de Modelos**: Permite comparar diferentes modelos o configuraciones de modelos de manera justa, usando el mismo esquema de validación.\n",
    "\n",
    "**Desventajas de cross_val_score()**\n",
    "\n",
    "* **Mayor Costo Computacional**: Requiere entrenar y evaluar el modelo múltiples veces (una vez por cada fold), lo que puede ser computacionalmente costoso, especialmente con modelos complejos o grandes conjuntos de datos.\n",
    "* **Configuración del Modelo**: Puede ser complicado seleccionar los parámetros adecuados para la validación cruzada (e.g., número de folds).\n",
    "* **Varianza en los Resultados**: Aunque reduce la varianza respecto a una simple partición de datos, los resultados de cross-validation pueden aún mostrar variabilidad significativa, especialmente con conjuntos de datos pequeños.\n",
    "\n",
    "**Parámetro scoring y el neg_mean_absolute_error**\n",
    "* En cross_val_score(), el parámetro **scoring** se utiliza para especificar la métrica de evaluación del modelo.\n",
    "* Cuando se utiliza **neg_mean_absolute_error**, se está indicando que se debe usar el error absoluto medio (MAE, por sus siglas en inglés) como métrica, pero en forma negativa.\n",
    "* Esto se hace porque Scikit-Learn espera que las métricas de evaluación a maximizar sean positivas (como precisión, R^2, etc.).\n",
    "* Dado que MAE es una métrica de error, menor es mejor, y por ello se usa el valor negativo para que un MAE menor (mejor) se traduzca en un valor negativo más alto (menos negativo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El uso de la validación cruzada produce una medida mucho mejor de la calidad del modelo, con el beneficio adicional de limpiar nuestro código: tenga en cuenta que ya no necesitamos realizar un seguimiento de los conjuntos de capacitación y validación por separado.\n",
    "* Entonces, especialmente para conjuntos de datos pequeños, ¡es una buena mejora!\n",
    "* **No se necesita hacer la partición en X_train, X_valid, y_train, y_valid**. Se trabaja directamente sobre X, y definidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Machine Learning para estimar pecios de viviendas\n",
    "\n",
    "* Se utliza los datos de la Competencia de precios de vivienda para usuarios de Kaggle Learn(https://www.kaggle.com/c/home-data-for-ml-course), donde utilizará 79 variables explicativas diferentes (como el tipo de techo, la cantidad de dormitorios y la cantidad de baños) para predecir los precios de las viviendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Leer los datos\n",
    "train_data = pd.read_csv('train.csv', index_col='Id')\n",
    "test_data = pd.read_csv('test.csv', index_col='Id')\n",
    "\n",
    "# 2. Eliminar filas con valores faltantes en la variable objetivo\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "# 2.1 Separar variable objetivo de las predictoras\n",
    "y = train_data.SalePrice\n",
    "train_data.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de train_data: (1460, 79)\n",
      "El tamaño de test_data: (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Tamaño de los dataframe\n",
    "print(f\"El tamaño de train_data: {train_data.shape}\")\n",
    "print(f\"El tamaño de test_data: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. \"Cardinalidad\" significa la cantidad de valores únicos en una columna\n",
    "# Seleccione columnas categóricas con cardinalidad relativamente baja (conveniente pero arbitraria)\n",
    "categorical_cols = [cname for cname in train_data.columns if\n",
    "                    train_data[cname].nunique() < 10 and\n",
    "                    train_data[cname].dtype == \"object\"]\n",
    "\n",
    "# 4. Selecciona columnas numéricas\n",
    "numerical_cols = [cname for cname in train_data.columns if\n",
    "                train_data[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# 5. Mantenga solo las columnas seleccionadas\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X = train_data[my_cols].copy()\n",
    "X_test =test_data[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de X: (1460, 76)\n",
      "El tamaño de X_test : (1459, 76)\n"
     ]
    }
   ],
   "source": [
    "# Tamaño de los dataframe despues de aplicar cardinalidad\n",
    "print(f\"El tamaño de X: {X.shape}\")\n",
    "print(f\"El tamaño de X_test : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construccion de Pipeline\n",
    "* Construir pipeline con scikit-learn.\n",
    "* El siguiente Pipeline utilizará SimpleImputer() para reemplazar los valores faltantes en los datos (numéricos y categóricos), antes de usar RandomForestRegressor() para entrenar un modelo de bosque aleatorio y luego hacer las predicciones.\n",
    "* Establecemos la cantidad de árboles en el modelo de bosque aleatorio con el parámetro n_estimators, y establecer random_state garantiza la reproducibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pipeline para reemplazar valores faltantes y modelar con RandomForestRegressor()\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# 1. Preprocesamiento de datos numéricos\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# 2. Preprocesamiento de datos categóricos\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 3. Preprocesamiento de paquetes para datos numéricos y categóricos\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# 4. Definir el modelo de Machine Learning\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# 5. Agrupar código de preprocesamiento y modelado en una canalización\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada\n",
    "* El siguiente código utiliza la función **cross_val_score()** para obtener el error absoluto medio (MAE), promediado en cinco pliegues diferentes.\n",
    "* El número de pliegues se configura con el parámetro cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score: 17684.78860958904\n"
     ]
    }
   ],
   "source": [
    "# Validadción Cruzada_Calculo del MAE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos de prueba. X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([127898.5 , 154677.4 , 178920.4 , ..., 152289.58, 111723.25,\n",
       "       226310.29])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Ajustar el pipeline completo con todo el conjunto de entrenamiento\n",
    "my_pipeline.fit(X, y)\n",
    "\n",
    "# 2. Predecir con los datos de prueba\n",
    "preds_test = my_pipeline.predict(X_test)\n",
    "\n",
    "# 3. Mostrar las predicciones\n",
    "preds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Guardar predicciones en un archivo\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
